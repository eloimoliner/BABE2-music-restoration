do_test: True #boolean flag to run inference, False means no testing at all

type: "blind"

name: "tester_blind_bwe" #same as the file name, try to do that for all testers

callable: 'testing.evaluator.Evaluator'
sampler_callable: 'testing.sampler_BABE2.BlindSampler'

modes: ['single_recording'] #modes to test

T: 51  #number of discretizatio steprs
#T: 70 #number of discretizatio steprs
order: 2 #order of the discretization TODO: implement higher order samplers as the one used in ediffi

filter_out_cqt_DC_Nyq: True

#checkpoint: "testing_training_code-400000.pt"
checkpoint: "weights-489999.pt"
base_checkpoint: None


#checkpoint_operator: "train_filters_diffusion_larger-250000.pt"

evaluation:
  path_dataset: "/scratch/elec/t412-asp/audio_datasets/archive_piano/historical_piano_50"
  single_recording: "78_1-mazurka-in-a-flat-major-op-59-no-2-2-mazurka-in-c-major-op-68-no-1_ar_gbia0226690a/1. MAZURKA IN A FLAT MAJOR (Op. 59, No. - Artur Rubinstein.flac_denoised.wav"
  start_s: [30,] #in seconds
  segment_length: 184184 #in samples
  num_segments_batch: 1
  segment_placement: "middle" #random, middle or start_s
  #csv_file: "piano_LTAS.csv" #for multiple recordings mode
  csv_file: "piano_recordings.csv" #for multiple recordings mode
  LTAS_init: True
  LTAS_as_y: True
  LTAS_file: "/scratch/work/molinee2/projects/BABE2/evaluation/LTAS_maestro_train_2018.pt"
  num_recordings: 1 
  process_complete_mode: "Block-Autoregressive" #or "Time-Invariant"
  overlap: 0.1


unconditional:
  num_samples: 8
  audio_len: 184184

posterior_sampling:
  xi: 1.0 # ) (between 0.4 and 0.8a for l2_sum)

  annealing_y:
    use: True
    mode: "fixed"
    sigma_min: 0.25

  grad_clipping: False
  clip_value: 0.5
  data_consistency: False #always False for blind bwe
  compensate_transition: True

  stft_distance:
    mag: False
    use: False
    use_multires: False
    nfft: 2048

  norm: 2  #"smoothl1" #1 or 2 or "smoothl1"

  SNR_observations: "None"  #adding noise helps to stabilize the inference
  #sigma_observations: 0.01 #adding noise is critical!
  sigma_observations: None #adding noise is critical!
  start_sigma: 0.5
  freq_weighting: "None"
  freq_weighting_filter: "sqrt"
  normalization: "grad_norm"

#new diffusion parameters (only for sampling):
diff_params:
  same_as_training: False
  sigma_data: 0.063 #default for maestro
  sigma_min: 4e-5
  sigma_max: 1
  P_mean: -1.2 #what is this for?
  P_std: 1.2 #ehat is this for?
  ro: 13
  ro_train: 13
  Schurn: 10
  Snoise: 1.000
  Stmin: 0
  Stmax: 50


bandwidth_extension:
  sigma_observations: 0.00 #adding noise is critical!
  #start_sigma: "None" #this is the initial noise level, applied to the observations as the first step of the inference, "None" means start from sigma_max

  gain_boost: 0 #db boost to the gain of the audio signal

  test_filter_fit: False #testing fitting for blind bwe experiments
  compute_sweep: False #also logging stuff for blind bwe experiments
  decimate:
    factor: 1
  filter:
    type: "firwin" #or "cheby1_fir"
    fc: 1000 #cutoff frequency of the applied lpf
    order: 500
    fir_order: 500
    beta: 1
    ripple: 0.05 #for the cheby1
    resample:
      fs: 2000
    biquad:
      Q: 0.707

inpainting:
  gap_length: 1000 #in ms
  start_gap_idx: None #in ms, None means at the middle
comp_sens: 
  percentage: 5 #%
phase_retrieval:
  win_size: 1024
  hop_size: 256
max_thresh_grads: 1
type_spec: "linear" #or "mel" for phase retrieval
declipping:
  SDR: 3 #in dB

       
real_informed_bwe:
  filter:
    fc: [2500, 4000]
    A: [-40, -45]
  apply_filter_in_observations: False #WARNING set to False



blind_bwe: #this involves generative model of filters
  #num_slopes: 1
  lr_filter: 10
  num_x_updates_per_step: 1
  num_filter_updates_per_step: 100
  beta_eps: 0 #part of the noise that is deterministic
  weight_decay: 0
  clip_grad_norm: 1

  gain_boost: 0 #db boost to the gain of the audio signal
  sigma_norm: 0.07
  LTAS_fft: 2048
  #LTAS:               
  #  sample_rate: 44100
  #  audio_len: 368368
  #  path: "/scratch/work/molinee2/datasets/MAESTRO/LTAS_MAESTRO.pt"
  real_recordings:
    path: /scratch/work/molinee2/projects/ddpm/blind_bwe_diffusion/audio_examples/samples_listening_test_real/the_chosen_ones
    num_samples: 8
  #SNR_observations: 50
  #sigma_observations: 0.01 #adding noise is critical!
  SNR_observations: None #adding noise is critical!
  compute_sweep: False #also logging stuff for blind bwe experiments
  Gain:
    optimize_G: False

  fcmin: 11 #or a number
  fcmax: "nyquist" #or a number
  Amin: -40
  Amax: 40
  Alim: 80
  NFFT: 4096
  sigma_den_estimate: 0.000 #this is the noise level of the observations, used for regularization
  test_filter:
    fref: 900
    fc_p: [1000, 3000]
    A_p: [0, -20, -30]
    fc_m: [700, 100]
    A_m: [0, 0, 0]
  initial_conditions:
    fref: 1000
    fc_p: [   1500,   2000]
    A_p: [0, 0,-80]
    fc_m: [500,  50]
    A_m: [0,0, 80 ]
  optimization: 
    #backtracking_enabled: True
    max_iter: 100
    grad_clip: 1
    #alpha: 0.2
    #beta: 0.5
    tol: [1e-1, 1e-1]
    #mu: [1000, 10]
    #lr: 10
    #weights: [10, 0.1]
    clamp_fc: True
    clamp_A: True
    block_low_freq: False
    only_negative_Ap: False
    last_slope_fixed: True #if True, the last slope of A_p is fixed to -40dB/oct
    first_slope_fixed: True #if True, the last slope of A_m is fixed to 40dB/oct
       
collapse_regularization:
  use: True
  beta: 0.1 #the smaller the fatter the loss, so more regularization
  gamma: 1
  lambda_reg: 10 #this is the weight of the regularization term (the cost is normalized between 0 and 1)


denoiser:
  callable: 'networks.denoiser.MultiStage_denoise'
  checkpoint: '/scratch/work/molinee2/projects/ddpm/blind_bwe_diffusion/experiments_denoiser/pretrained_model/checkpoint_denoiser'
  sample_rate_denoiser: 22050
  segment_size: 5 #in seconds
  activation: "elu"
  use_csff: False
  use_SAM: True
  use_cam: False
  use_fam: False
  use_fencoding: True
  use_tdf: False
  use_alttdfs: False
  num_tfc: 3
  num_stages: 2
  depth: 6
  f_dim: 513 #hardcoded, depends on the stft window
  stft_win_size: 1024
  stft_hop_size: 256

   
wandb:
  use: False
  entity: "eloimoliner"
  project: "blind_restoration"
  run_name: "fc_A"
  heavy_log_interval: 10
